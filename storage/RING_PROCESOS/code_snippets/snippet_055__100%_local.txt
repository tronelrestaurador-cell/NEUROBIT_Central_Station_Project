python






















1



2



3



4



5



6



7



8



9



10



11



12



13



14



15



16



17



18



19



20



21



22



23



24



25





26



27





28



29



30





31



32





33



34



35



36





37



38



39





40



41



42



43



44





45



46





47





48



49





50



51



52





53



54



55



56





57



58



59



60



61



62



63



64



65



66



67



68



69





70



71





72



73



74



75



76



77



78



79



80



81



82



83



84





85



86



87



88



89



90



91



92



93





94



95





96



97



98



99



100



101



102



103



104



105



106



107



108



109



110



111



112



113





114



115



116



117



118





119



120



121



122





123



124



125



126



127





128



129



130



131



132



133





134





135



136



137



138





139



140



141



142



143



144



145



146



147



148



149





150



151



152



153



154



155





156



157



158



159



160



161





162





163



164



165



166



167



168



169





170



171



172



173



174



175



176



177



178





179





180



181





182



183



184



185



186



187



188





189



190



191



192



193



194





195



196



197



198



199



200



201



202



203





204



205



206



207



208



209



210



211



212



213





214



215





216



217



218



219



220



221



222



223



224



225



226



227



228



229



230





231





232



233



234



235





236



237



238



239



240



241





242



243



244



245



246



247



248



249



250





251





252



253



254



255



256





257



258



259



260



261





262



263



264



265



266



267



268



269





270





271



272



273





274





275



276



277



278





279



280



281



282



283



284



285



286



287





288



289



290





291





292



293



294



295



296



297





298



299



300



301



302





303



304



305



306



307



308



309



310



311



312





313



314



315





316



317



318





319



320



321





322



323



324



325





326



327



328



329



330





331



332



333



334



335



336





337



338



339



340



341



342



343





344



345



346



347



348





349



350



351



352



353



354



355





356



357



358



359





360



361



362





363



364



365





366



367





368



369



370





371



372



373



374



375



376





377



378



379





380



381



382



383



384



385



386



387



388



389



390





391



392



393



394



























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































#!/usr/bin/env python3

"""

coherence_filter.py

Implementación mínima para calcular scores Mental (M) y Emocional (E)

según modelo NEUROBIT v1.0



Dependencias mínimas:

pip install nltk spacy textblob sentencepiece



Configuración inicial:

python -m spacy download es_core_news_sm

"""



import re

import json

import yaml

import math

from datetime import datetime

from typing import Dict, List, Tuple, Optional

import nltk

from nltk.sentiment import SentimentIntensityAnalyzer

import spacy

from textblob import TextBlob



# Descargar recursos necesarios (solo primera ejecución)

try:

    nltk.data.find('vader_lexicon')

except LookupError:

    nltk.download('vader_lexicon')



try:

    nlp = spacy.load("es_core_news_sm")

except OSError:

    print("ERROR: Modelo spaCy no encontrado. Ejecutar: python -m spacy download es_core_news_sm")

    exit(1)



class CoherenceFilter:

    """Calcula scores Mental (M) y Emocional (E) para mensajes según modelo NEUROBIT"""

    

    def __init__(self, glossary_path: str = "config/memoria_sagrada_eva.yaml"):

        """Inicializa con glosario de términos y modelos de NLP"""

        self.glossary = self._load_glossary(glossary_path)

        self.sia = SentimentIntensityAnalyzer()

        

    def _load_glossary(self, path: str) -> Dict:

        """Carga glosario desde YAML con manejo de errores"""

        try:

            with open(path, 'r', encoding='utf-8') as f:

                return yaml.safe_load(f)

        except FileNotFoundError:

            print(f"ADVERTENCIA: Glosario no encontrado en {path}. Usando diccionario vacío.")

            return {"entries": []}

        except Exception as e:

            print(f"ERROR al cargar glosario: {e}")

            return {"entries": []}

    

    def calculate_plane_scores(self, text: str) -> Tuple[float, float]:

        """

        Calcula scores Mental (M) y Emocional (E) según modelo NEUROBIT

        Retorna: (M_score, E_score) en rango [-1.0, 1.0]

        """

        # Calcular score mental (coherencia lógica)

        m_score = self._calculate_mental_score(text)

        

        # Calcular score emocional (carga afectiva)

        e_score = self._calculate_emotional_score(text)

        

        return (round(m_score, 2), round(e_score, 2))

    

    def _calculate_mental_score(self, text: str) -> float:

        """Calcula score Mental (M) basado en coherencia lógica y semántica"""

        if not text.strip():

            return 0.0

            

        # 1. Análisis de coherencia lógica básica

        logical_coherence = self._assess_logical_coherence(text)

        

        # 2. Detección de ambigüedades terminológicas

        ambiguity_score = self._assess_ambiguity(text)

        

        # 3. Densidad semántica (información útil vs ruido)

        semantic_density = self._calculate_semantic_density(text)

        

        # Combinar métricas con pesos definidos

        m_score = (

            0.5 * logical_coherence +

            0.3 * (1 - ambiguity_score) +  # Menos ambigüedad = mejor score

            0.2 * semantic_density

        )

        

        # Normalizar a rango [-1.0, 1.0] con límites realistas

        return max(-1.0, min(1.0, m_score * 1.5 - 0.5))

    

    def _calculate_emotional_score(self, text: str) -> float:

        """Calcula score Emocional (E) basado en carga afectiva y señales de trauma"""

        if not text.strip():

            return 0.0

            

        # 1. Análisis de sentimiento básico (VADER)

        sentiment = self.sia.polarity_scores(text)

        

        # 2. Detección de señales de trauma/estrés

        trauma_signals = self._detect_trauma_signals(text)

        

        # 3. Intensidad emocional (valencia + activación)

        emotional_intensity = self._assess_emotional_intensity(text)

        

        # Combinar métricas

        # Sentimiento positivo aumenta E, negativo disminuye

        # Señales de trauma reducen drásticamente E

        e_score = sentiment['compound'] * (1 - trauma_signals * 0.7) * 0.8

        

        # Ajustar por intensidad (emociones muy intensas reducen control)

        if emotional_intensity > 0.7:

            e_score *= 0.6

        

        return max(-1.0, min(1.0, e_score))

    

    def _assess_logical_coherence(self, text: str) -> float:

        """Evalúa coherencia lógica básica del texto"""

        # Tokenizar y analizar estructura

        sentences = nltk.sent_tokenize(text)

        if not sentences:

            return 0.0

            

        # 1. Detección de contradicciones básicas

        contradiction_count = 0

        contradiction_pairs = [

            ("no", "sí"), ("nunca", "siempre"), ("todos", "ninguno"),

            ("afirmo", "niego"), ("verdad", "mentira"), ("bien", "mal")

        ]

        

        text_lower = text.lower()

        for neg, pos in contradiction_pairs:

            if neg in text_lower and pos in text_lower:

                contradiction_count += 1

        

        # 2. Conectores lógicos (mayor coherencia con conectores adecuados)

        logical_connectors = ["por lo tanto", "sin embargo", "además", "en consecuencia", 

                             "por otro lado", "finalmente", "en resumen"]

        connector_count = sum(1 for conn in logical_connectors if conn in text_lower)

        

        # Calcular score

        base_score = 0.7  # Punto de partida realista

        base_score -= min(0.5, contradiction_count * 0.15)  # Penalizar contradicciones

        base_score += min(0.3, connector_count * 0.05)     # Recompensar conectores

        

        return max(0.0, min(1.0, base_score))

    

    def _assess_ambiguity(self, text: str) -> float:

        """Evalúa nivel de ambigüedad terminológica (0 = claro, 1 = muy ambiguo)"""

        ambiguous_terms = 0

        total_terms = 0

        

        # Términos comúnmente ambiguos en español

        ambiguous_keywords = [

            "norma", "ley", "poder", "libertad", "verdad", "justicia", 

            "derecho", "realidad", "ser", "deber", "bien", "mal"

        ]

        

        text_lower = text.lower()

        for term in ambiguous_keywords:

            if term in text_lower:

                ambiguous_terms += text_lower.count(term)

        

        # Contar palabras totales

        words = re.findall(r'\b\w+\b', text_lower)

        total_terms = len(words)

        

        if total_terms == 0:

            return 0.0

            

        # Calcular ratio de ambigüedad

        ambiguity_ratio = ambiguous_terms / total_terms

        

        # Ajustar con detección de polisemia usando spaCy

        doc = nlp(text)

        polysemic_count = 0

        for token in doc:

            if token.pos_ in ["NOUN", "VERB", "ADJ"] and len(token.text) > 3:

                # Palabras con múltiples acepciones tienden a ser más largas

                if len(token.text) > 6:

                    polysemic_count += 1

        

        polysemic_ratio = polysemic_count / max(1, len(doc))

        

        return min(1.0, ambiguity_ratio * 0.7 + polysemic_ratio * 0.3)

    

    def _calculate_semantic_density(self, text: str) -> float:

        """Calcula densidad de significado útil vs ruido"""

        # Usar TextBlob para análisis de contenido

        blob = TextBlob(text)

        

        # Palabras vacías en español (stopwords)

        stopwords = set([

            "el", "la", "los", "las", "un", "una", "unos", "unas", "y", "o", "pero",

            "porque", "que", "como", "con", "para", "en", "de", "a", "al", "del",

            "se", "su", "sus", "mi", "mis", "tu", "tus", "es", "son", "fue", "será"

        ])

        

        words = [word.lower() for word in re.findall(r'\b\w+\b', text) if len(word) > 2]

        meaningful_words = [w for w in words if w not in stopwords]

        

        if not words:

            return 0.0

            

        density = len(meaningful_words) / len(words)

        

        # Ajustar por diversidad léxica

        lexical_diversity = len(set(meaningful_words)) / max(1, len(meaningful_words))

        

        return min(1.0, density * 0.7 + lexical_diversity * 0.3)

    

    def _detect_trauma_signals(self, text: str) -> float:

        """Detecta señales de trauma o estrés emocional (0 = ninguna, 1 = alta)"""

        trauma_indicators = [

            # Palabras que indican experiencia traumática

            "dolor", "miedo", "terror", "angustia", "sufrimiento", "herida", "cicatriz",

            "abus", "violencia", "peligro", "amenaza", "trauma", "víctima", "culpa",

            # Patrones de lenguaje traumático

            "no puedo", "no puedo más", "me duele", "me mata", "me destruye",

            "odio", "odio a", "odio que", "nunca voy a", "siempre me"

        ]

        

        text_lower = text.lower()

        signal_count = sum(1 for indicator in trauma_indicators if indicator in text_lower)

        

        # Detección de repetición intensa (señal de fijación traumática)

        words = re.findall(r'\b\w+\b', text_lower)

        word_counts = {}

        for word in words:

            if len(word) > 3:

                word_counts[word] = word_counts.get(word, 0) + 1

        

        intense_repetition = any(count > 5 for count in word_counts.values())

        if intense_repetition:

            signal_count += 3

        

        # Normalizar a rango [0, 1]

        return min(1.0, signal_count * 0.15)

    

    def _assess_emotional_intensity(self, text: str) -> float:

        """Evalúa intensidad emocional (0 = neutro, 1 = muy intenso)"""

        # Usar VADER para intensidad básica

        sentiment = self.sia.polarity_scores(text)

        intensity = abs(sentiment['compound'])

        

        # Ajustar por signos de intensidad extrema

        extreme_signals = ["!!!", "???", "¡¡¡", "¿¿¿", "MUERE", "ODIO", "AMOR", "NUNCA", "SIEMPRE"]

        text_upper = text.upper()

        for signal in extreme_signals:

            if signal in text_upper:

                intensity += 0.2

        

        # Detección de mayúsculas excesivas (señal de intensidad)

        upper_ratio = sum(1 for c in text if c.isupper()) / max(1, len(text))

        if upper_ratio > 0.3:

            intensity += 0.3

        

        return min(1.0, intensity)

    

    def detect_ambiguities(self, text: str) -> List[Dict]:

        """Detecta términos ambiguos y sugiere acepciones del glosario"""

        ambiguities = []

        text_lower = text.lower()

        

        # Términos objetivo para desambiguación

        target_terms = ["norma", "ley", "poder", "libertad", "verdad", "justicia", "logos"]

        

        for term in target_terms:

            if term in text_lower:

                # Buscar en glosario

                glossary_match = None

                for entry in self.glossary.get("entries", []):

                    if entry.get("term", "").lower() == term:

                        glossary_match = entry

                        break

                

                ambiguities.append({

                    "term": term,

                    "context": self._extract_context(text, term),

                    "glossary_match": bool(glossary_match),

                    "recommended_acceptation": glossary_match.get("intensional_definition", "") if glossary_match else None

                })

        

        return ambiguities

    

    def _extract_context(self, text: str, term: str, window: int = 10) -> str:

        """Extrae contexto alrededor de un término"""

        words = text.split()

        for i, word in enumerate(words):

            if term.lower() in word.lower():

                start = max(0, i - window)

                end = min(len(words), i + window + 1)

                return " ".join(words[start:end])

        return ""



def generate_message_envelope(

    content: str, 

    entity_id: str = "HUMANO_TRON",

    perspective: str = "coordinacion",

    context: str = "RONDA_1"

) -> Dict:

    """

    Genera envelope completo para un mensaje según especificación NEUROBIT

    """

    filter = CoherenceFilter()

    m_score, e_score = filter.calculate_plane_scores(content)

    ambiguities = filter.detect_ambiguities(content)

    

    # Determinar cuadrante y acción recomendada

    quadrant = 1

    if m_score > 0.6 and e_score >= -0.3:

        quadrant = 1

        action = "store"

    elif m_score > 0.6 and e_score < -0.3:

        quadrant = 2

        action = "propose_reformulation"

    elif m_score <= 0.6 and e_score < -0.3:

        quadrant = 3

        action = "propose_reformulation"

    else:

        quadrant = 4

        action = "propose_reformulation"

    

    return {

        "message_id": f"msg_{datetime.now().strftime('%Y%m%d_%H%M%S')}",

        "entity_id": entity_id,

        "perspective": perspective,

        "context": context,

        "plane": {

            "M": m_score,

            "E": e_score

        },

        "intention": "analizar_mensaje",

        "content": content,

        "analysis": {

            "coherence_score": m_score,

            "emotional_score": e_score,

            "quadrant": quadrant,

            "identified_ambiguities": ambiguities,

            "suggested_reformulation": _generate_reformulation_suggestion(m_score, e_score, ambiguities)

        },

        "provenance": {

            "created": datetime.now().isoformat(),

            "signed_by": "SIMON"

        },

        "action": action,

        "human_approval": {

            "approved": False,

            "approver_id": "",

            "timestamp": ""

        }

    }



def _generate_reformulation_suggestion(m_score: float, e_score: float, ambiguities: List[Dict]) -> str:

    """Genera sugerencia de reformulación basada en scores y ambigüedades"""

    suggestions = []

    

    if m_score < 0.6:

        suggestions.append("Clarificar conceptos clave y eliminar ambigüedades")

    

    if e_score < -0.5:

        suggestions.append("Reducir carga emocional negativa y expresar intención constructiva")

    

    if ambiguities:

        ambiguous_terms = [amb["term"] for amb in ambiguities if amb["glossary_match"]]

        if ambiguous_terms:

            suggestions.append(f"Especificar acepción para términos: {', '.join(ambiguous_terms)}")

    

    if not suggestions:

        return "Mensaje coherente y con tono apropiado. Sin sugerencias de mejora."

    

    return " | ".join(suggestions)



# Ejemplo de uso (para prueba rápida)

if __name__ == "__main__":

    ejemplo = "Esa norma es ilegítima y debe desaparecer. No toleraré más esta injusticia."

    

    envelope = generate_message_envelope(

        content=ejemplo,

        entity_id="HUMANO_TRON",

        perspective="coordinacion",

        context="PRUEBA_TECNICA"

    )

    

    print("Envelope generado para NEUROBIT:")

    print(json.dumps(envelope, indent=2, ensure_ascii=False))

    

    # Guardar ejemplo para documentación

    with open("ejemplo_envelope_neurobit.json", "w", encoding="utf-8") as f:

        json.dump(envelope, f, indent=2, ensure_ascii=False)

    

    print(f"\nEjemplo guardado en: ejemplo_envelope_neurobit.json")
